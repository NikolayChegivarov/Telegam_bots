from docx import Document
from docx.shared import Parented
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from pprint import pprint
import zipfile
import re
import xml.etree.ElementTree as ET
import docx2txt
from docx.table import Table
import os


def extract_inn_ogrn(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ò–ù–ù –∏ –û–ì–†–ù –∏–∑ —Å—Ç—Ä–æ–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ò–ù–ù/–û–ì–†–ù, –∞ —Ç–∞–∫–∂–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è."""
    inn_match = re.search(r'\b–ò–ù–ù[\s:\xa0]*([0-9]{10,12})\b', text)
    ogrn_match = re.search(r'\b–û–ì–†–ù[\s:\xa0]*([0-9]{13})\b', text)

    inn = inn_match.group(1) if inn_match else ''
    ogrn = ogrn_match.group(1) if ogrn_match else ''

    # –£–¥–∞–ª–∏–º –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤—Å–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –ò–ù–ù –∏ –û–ì–†–ù
    cleaned_text = re.sub(r'–ò–ù–ù[\s:\xa0]*[0-9]{10,12}', '', text)
    cleaned_text = re.sub(r'–û–ì–†–ù[\s:\xa0]*[0-9]{13}', '', cleaned_text)
    cleaned_text = cleaned_text.strip(" ,‚Äì‚Äî\u2002")

    return cleaned_text, inn, ogrn


def extract_text_from_cell(cell):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –Ω–µ–ø—É—Å—Ç—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —è—á–µ–π–∫–∏."""
    return '\n'.join(
        paragraph.text.strip()
        for paragraph in cell.paragraphs
        if paragraph.text.strip()
    ).strip()


def extract_text_without_strikethrough(paragraph):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞, –∏—Å–∫–ª—é—á–∞—è –∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–µ —á–∞—Å—Ç–∏."""
    return ''.join(run.text for run in paragraph.runs if not is_strikethrough(run))


def is_strikethrough(run):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–º."""
    if run.font.strike:
        return True
    rPr = run._element.get_or_add_rPr()
    strike = rPr.find(qn('w:strike'))
    if strike is not None and strike.get(qn('w:val')) != '0':
        return True
    return False


def extract_competitive_manager(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—É—Ä—Å–Ω–æ–º —É–ø—Ä–∞–≤–ª—è—é—â–µ–º –∏–∑ —Ç–∞–±–ª–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    target_keys = [
        "–ò—Å–ø–æ–ª–Ω—è—é—â–∏–π –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—É—Ä—Å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª—è—é—â–µ–≥–æ",
        "–ö–æ–Ω–∫—É—Ä—Å–Ω—ã–π —É–ø—Ä–∞–≤–ª—è—é—â–∏–π"
    ]

    for table in doc.tables:
        for row in table.rows:
            if len(row.cells) < 2:
                continue

            key = extract_text_from_cell(row.cells[0])
            value = extract_text_from_cell(row.cells[1])

            if any(target.lower() in key.lower() for target in target_keys):
                return split_director_info(value)

    return {'–§–ò–û': '', '–ò–ù–ù': ''}


def split_director_info(text):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –§–ò–û –∏ –ò–ù–ù, –æ—á–∏—â–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã."""
    cleaned = re.sub(r'[\u00A0\s]', '', text)  # —É–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    match = re.search(r'(\d{10}|\d{12})', cleaned)

    if match:
        inn = match.group(1)
        # –Ω–∞–π—Ç–∏, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ò–ù–ù, –∏ –æ—Ç—Ä–µ–∑–∞—Ç—å –≤—Å—ë –¥–æ –Ω–µ–≥–æ –¥–ª—è –§–ò–û
        raw_fio = text[:text.find('–ò–ù–ù')].strip(' ,')
        return {'–§–ò–û': raw_fio, '–ò–ù–ù': inn}
    else:
        return {'–§–ò–û': text.strip(), '–ò–ù–ù': ''}


def clean_sum_text(sum_text):
    """–ü—Ä–∏–≤–æ–¥–∏—Ç —Å—É–º–º—É –∫ —Ñ–æ—Ä–º–∞—Ç—É '1000000,00' (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤, —Å–∏–º–≤–æ–ª–æ–≤ –≤–∞–ª—é—Ç—ã –∏ –ø—Ä–æ—á–µ–≥–æ —Ç–µ–∫—Å—Ç–∞)."""
    if not sum_text:
        return ''
    cleaned = sum_text.replace('\xa0', '').replace(' ', '')
    cleaned = re.sub(r'—Ä—É–±(\.|–ª—å)?|—Ä\.|‚ÇΩ', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'[^\d,]', '', cleaned)
    cleaned = cleaned.replace('.', ',')
    if cleaned.count(',') > 1:
        first = cleaned.find(',')
        cleaned = cleaned[:first + 1] + cleaned[first + 1:].replace(',', '')
    return cleaned


def extract_first_address_block(full_address: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –ª–æ–≥–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π –∞–¥—Ä–µ—Å–Ω—ã–π –±–ª–æ–∫ –∏–∑ –ø–æ–ª–Ω–æ–π —Å—Ç—Ä–æ–∫–∏.
    –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –Ω–æ–≤—ã–µ –±–ª–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 115280).
    """
    match = list(re.finditer(r'\b1\d{5}\b', full_address))  # –∏—â–µ–º –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã

    if len(match) >= 2:
        return full_address[:match[1].start()].rstrip(', ')
    return full_address.strip(', ')


def extract_basic_info(doc):
    basic_info = {
        '–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': '',
        '–ò–ù–ù': '',
        '–ö–ü–ü': '',
        '–û–ì–†–ù': '',
        '–î–∞—Ç–∞ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è': '',
        '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å': [],
        '–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª': '',
        '–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä': '',
        '–û–ö–í–≠–î(–æ—Å–Ω–æ–≤–Ω–æ–π)': ''
    }

    for table in doc.tables:
        for row in table.rows:
            cells = row.cells
            if len(cells) < 2:
                continue

            key = extract_text_from_cell(cells[0])
            value = extract_text_from_cell(cells[1])

            if not key and not value:
                continue

            # print(f"–ö–ª—é—á: {key!r} | –ó–Ω–∞—á–µ–Ω–∏–µ: {value!r}")  # üêû –û—Ç–ª–∞–¥–∫–∞

            if "–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ" in key:
                basic_info['–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'] = value
            elif key == "–ò–ù–ù":
                basic_info['–ò–ù–ù'] = value
            elif key == "–ö–ü–ü":
                basic_info['–ö–ü–ü'] = value
            elif key == "–û–ì–†–ù":
                basic_info['–û–ì–†–ù'] = value
            elif key == "–î–∞—Ç–∞ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è":
                basic_info['–î–∞—Ç–∞ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è'] = value
            elif "–Æ—Ä. –∞–¥—Ä–µ—Å" in key or "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å" in key:
                if value:
                    basic_info['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å'].extend(value.split('\n'))
            elif "–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª" in key and not basic_info['–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª']:
                basic_info['–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª'] = value
            elif "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä" in key:
                basic_info['–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä'] = split_director_info(value)
            elif "–û—Å–Ω–æ–≤–Ω–æ–π –≤–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏" in key:
                basic_info['–û–ö–í–≠–î(–æ—Å–Ω–æ–≤–Ω–æ–π)'] = value

    raw_address = ', '.join(
        addr.strip() for addr in basic_info['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å'] if addr.strip())
    basic_info['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å'] = extract_first_address_block(raw_address)

    return basic_info


def extract_staff_info(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö: —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –∏ —Å—Ä–µ–¥–Ω—é—é –∑–∞—Ä–ø–ª–∞—Ç—É."""
    staff_info = {
        '–°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å': {'year_1': '', 'year_2': '', 'year_3': ''},
        '–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞': {'year_1': '', 'year_2': '', 'year_3': ''}
    }
    staff_years_count = {}
    staff_years_salary = {}

    for table in doc.tables:
        rows = table.rows
        i = 0
        while i < len(rows):
            cells = rows[i].cells
            key = extract_text_without_strikethrough(cells[0].paragraphs[0]).strip().lower() if cells[0].paragraphs else ''
            value = extract_text_without_strikethrough(cells[1].paragraphs[0]).strip() if len(cells) > 1 and cells[1].paragraphs else ''

            # –°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å
            if '—Å—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á' in key:
                text_block_count = value
                j = i + 1
                while j < len(rows):
                    next_key = extract_text_without_strikethrough(rows[j].cells[0].paragraphs[0]).strip().lower() if rows[j].cells[0].paragraphs else ''
                    next_value = extract_text_without_strikethrough(rows[j].cells[1].paragraphs[0]).strip() if len(rows[j].cells) > 1 and rows[j].cells[1].paragraphs else ''
                    if next_key:
                        break
                    text_block_count += "\n" + next_value
                    j += 1
                matches = re.findall(r'–∑–∞\s+(\d{4}):\s*([0-9]+)', text_block_count)
                for year, val in matches:
                    staff_years_count[year] = val
                i = j
                continue

            # –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞
            elif '—Å—Ä–µ–¥–Ω—è—è –∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞' in key or '—Å—Ä–µ–¥–Ω–µ–º–µ—Å—è—á–Ω–∞—è –∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞' in key:
                text_block_salary = value
                j = i + 1
                while j < len(rows):
                    next_key = extract_text_without_strikethrough(rows[j].cells[0].paragraphs[0]).strip().lower() if rows[j].cells[0].paragraphs else ''
                    next_value = extract_text_without_strikethrough(rows[j].cells[1].paragraphs[0]).strip() if len(rows[j].cells) > 1 and rows[j].cells[1].paragraphs else ''
                    if next_key:
                        break
                    text_block_salary += "\n" + next_value
                    j += 1
                matches = re.findall(r'–∑–∞\s+(\d{4}):\s*([\d\s]+)', text_block_salary)
                for year, val in matches:
                    salary_clean = clean_sum_text(val)
                    staff_years_salary[year] = salary_clean
                i = j
                continue

            i += 1

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    slots = ['year_1', 'year_2', 'year_3']
    for idx, year in enumerate(sorted(staff_years_count.keys(), reverse=True)[:3]):
        staff_info['–°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å'][slots[idx]] = f"{{'{year}': '{staff_years_count[year]}'}}"

    for idx, year in enumerate(sorted(staff_years_salary.keys(), reverse=True)[:3]):
        staff_info['–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞'][slots[idx]] = f"{{'{year}': '{staff_years_salary[year]}'}}"

    return staff_info


def extract_founders(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—á—Ä–µ–¥–∏—Ç–µ–ª—è—Ö,
    –¥–µ–ª—è –∏—Ö –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∏ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –ø–æ –∑–∞—á–µ—Ä–∫–Ω—É—Ç–æ—Å—Ç–∏ –§–ò–û –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—é –¥–æ–ª–∏."""
    actual = []
    outdated = []

    for table in doc.tables:
        header = [extract_text_without_strikethrough(cell.paragraphs[0]).strip().lower()
                  for cell in table.rows[0].cells if cell.paragraphs]

        col_map = {'share': None, 'sum': None, 'name': None, 'date': None}
        for idx, text in enumerate(header):
            if '–¥–æ–ª—è' in text and '%' in text:
                col_map['share'] = idx
            elif '—Ä—É–±' in text or '–≤–∫–ª–∞–¥' in text or '—Å—É–º–º–∞' in text:
                col_map['sum'] = idx
            elif '—É—á–∞—Å—Ç–Ω–∏–∫' in text or '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' in text or '—Ñ–∏–æ' in text:
                col_map['name'] = idx
            elif '–¥–∞—Ç–∞' in text:
                col_map['date'] = idx

        if not all(col_map[k] is not None for k in ('share', 'sum', 'name')):
            continue

        i = 1
        while i < len(table.rows):
            row = table.rows[i]
            cells = row.cells

            def get_full_text(cell):
                return '\n'.join(p.text.strip() for p in cell.paragraphs if p.text.strip()).strip()

            def has_strikethrough(cell):
                for p in cell.paragraphs:
                    for run in p.runs:
                        if is_strikethrough(run) and run.text.strip():
                            return True
                return False

            share = get_full_text(cells[col_map['share']]) if col_map['share'] < len(cells) else ''
            summ = get_full_text(cells[col_map['sum']]) if col_map['sum'] < len(cells) else ''
            name_cell = cells[col_map['name']] if col_map['name'] < len(cells) else None
            name = get_full_text(name_cell) if name_cell else ''
            has_strike = has_strikethrough(name_cell) if name_cell else False
            date = get_full_text(cells[col_map['date']]) if col_map['date'] is not None and col_map['date'] < len(cells) else ''

            # –ü–æ–ø—ã—Ç–∫–∞ –≤–∑—è—Ç—å –¥–∞—Ç—É –∏–∑ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–∏
            if not date and i + 1 < len(table.rows):
                next_row = table.rows[i + 1]
                if next_row.cells and next_row.cells[0].paragraphs:
                    candidate = extract_text_without_strikethrough(next_row.cells[0].paragraphs[0]).strip()
                    if re.match(r'\d{2}\.\d{2}\.\d{4}', candidate):
                        date = candidate
                        i += 1

            name_clean, inn, _ = extract_inn_ogrn(name)
            full_name = f"{name_clean}, –ò–ù–ù {inn}".strip(', ') if inn else name_clean

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏
            record = {
                "–î–æ–ª—è –≤ %": share,
                "–î–æ–ª—è –≤ —Ä—É–±": clean_sum_text(summ),
                "–ù–∞–∏–º–µ–Ω. –∏ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã": full_name,
                "–î–∞—Ç–∞": date
            }

            if any(record.values()):
                # –ö—Ä–∏—Ç–µ—Ä–∏–π –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏: –∑–∞—á—ë—Ä–∫–Ω—É—Ç –ò–õ–ò –¥–æ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/—Ä–∞–≤–Ω–∞ '‚Äì'
                if has_strike or share.strip() == '‚Äì' or not share.strip():
                    outdated.append(record)
                else:
                    actual.append(record)

            i += 1

    return {
        "–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏": actual,
        "–ù–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏": outdated
    }


def extract_collaterals(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç '–ó–∞–ª–æ–≥–æ–¥–∞—Ç–µ–ª—å', '–ó–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å' –∏ '–î–∞—Ç–∞ –∑–∞–ª–æ–≥–∞'
    –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∑–∞—á—ë—Ä–∫–Ω—É—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
    collaterals = []

    date_pattern = re.compile(r'–æ—Ç\s+(\d{2}\.\d{2}\.\d{4})')

    for table in doc.tables:
        collateral_entry = {
            '–ó–∞–ª–æ–≥–æ–¥–∞—Ç–µ–ª—å': '',
            '–ó–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å': '',
            '–î–∞—Ç–∞ –∑–∞–ª–æ–≥–∞': ''
        }

        for row in table.rows:
            cells = row.cells
            if len(cells) < 2:
                continue

            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —è—á–µ–π–∫–∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            left = ' '.join(p.text.strip() for p in cells[0].paragraphs if p.text.strip()).strip()
            right = ' '.join(p.text.strip() for p in cells[1].paragraphs if p.text.strip()).strip()

            if '–∑–∞–ª–æ–≥–æ–¥–∞—Ç–µ–ª—å' in left.lower() and not collateral_entry['–ó–∞–ª–æ–≥–æ–¥–∞—Ç–µ–ª—å']:
                collateral_entry['–ó–∞–ª–æ–≥–æ–¥–∞—Ç–µ–ª—å'] = right
                continue

            if '–∑–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å' in left.lower() and not collateral_entry['–ó–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å']:
                collateral_entry['–ó–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å'] = right
                continue

            if '–¥–æ–≥–æ–≤–æ—Ä' in left.lower() or '–¥–æ–≥–æ–≤–æ—Ä' in right.lower():
                match = date_pattern.search(left + ' ' + right)
                if match and not collateral_entry['–î–∞—Ç–∞ –∑–∞–ª–æ–≥–∞']:
                    collateral_entry['–î–∞—Ç–∞ –∑–∞–ª–æ–≥–∞'] = match.group(1)

        if any(collateral_entry.values()):
            collaterals.append(collateral_entry)

    return collaterals


def extract_leasing_info(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏–∑–∏–Ω–≥–µ."""
    leasing_info_all = []
    for table in doc.tables:
        if len(table.columns) != 2 or len(table.rows) < 5:
            continue

        first_cell_text = extract_text_without_strikethrough(table.cell(0, 0).paragraphs[0]).strip()
        if not re.match(r'\d{2}\.\d{2}\.\d{4}', first_cell_text):
            continue

        data = {
            "–õ–∏–∑–∏–Ω–≥–æ–¥–∞—Ç–µ–ª—å": "",
            "–ü–µ—Ä–∏–æ–¥ –ª–∏–∑–∏–Ω–≥–∞": "",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": "",
            "–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å": ""
        }

        for row in table.rows:
            key = extract_text_without_strikethrough(row.cells[0].paragraphs[0]).strip().lower()
            value = extract_text_without_strikethrough(row.cells[1].paragraphs[0]).strip()

            if key.startswith("–ª–∏–∑–∏–Ω–≥–æ–¥–∞—Ç–µ–ª—å"):
                if "–°–≤–µ–¥–µ–Ω–∏—è —Å–∫—Ä—ã—Ç—ã" in value:
                    data["–õ–∏–∑–∏–Ω–≥–æ–¥–∞—Ç–µ–ª—å"] = "–°–≤–µ–¥–µ–Ω–∏—è —Å–∫—Ä—ã—Ç—ã"
                else:
                    name, inn, ogrn = extract_inn_ogrn(value)
                    data["–õ–∏–∑–∏–Ω–≥–æ–¥–∞—Ç–µ–ª—å"] = f"{name}, –ò–ù–ù {inn}, –û–ì–†–ù {ogrn}".strip(', ')
            elif key.startswith("–ø–µ—Ä–∏–æ–¥ –ª–∏–∑–∏–Ω–≥–∞"):
                data["–ü–µ—Ä–∏–æ–¥ –ª–∏–∑–∏–Ω–≥–∞"] = value
            elif key.startswith("–∫–∞—Ç–µ–≥–æ—Ä–∏—è"):
                data["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] = value
            elif key.startswith("—Å—Ç–∞—Ç—É—Å"):
                data["–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å"] = value.split('\n')[0].strip()

        if data["–õ–∏–∑–∏–Ω–≥–æ–¥–∞—Ç–µ–ª—å"] or data["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"]:
            leasing_info_all.append(data)

    not_finished = [
        x for x in leasing_info_all
        if '–∑–∞–≤–µ—Ä—à–∏–ª—Å—è' not in x.get('–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å', '').lower()
    ]
    if not leasing_info_all:
        return ["–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –ª–∏–∑–∏–Ω–≥—É –Ω–µ—Ç"]
    if not not_finished:
        return ["–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –ª–∏–∑–∏–Ω–≥—É —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º '–î–µ–π—Å—Ç–≤—É–µ—Ç' –Ω–µ—Ç"]
    return not_finished


def extract_credit_debt(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏."""
    for table in doc.tables:
        headers = [extract_text_without_strikethrough(cell.paragraphs[0]).lower()
                   for cell in table.rows[0].cells if cell.paragraphs]
        if (len(headers) >= 4
                and any('–∫–æ–¥' in h for h in headers)
                and sum(re.search(r'20\d{2}', h) is not None for h in headers) >= 2):

            debt_row = None
            for row in table.rows:
                if extract_text_without_strikethrough(row.cells[0].paragraphs[0]).strip().lower().startswith(
                        "–∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å"):
                    debt_row = row
                    break

            if debt_row:
                year_val = {}
                for idx, cell in enumerate(headers):
                    year_match = re.search(r'(20\d{2})', cell)
                    if year_match and idx < len(debt_row.cells):
                        year = year_match.group(1)
                        value = extract_text_without_strikethrough(debt_row.cells[idx].paragraphs[0]).strip().replace(
                            ' ', '').replace('‚Äì', '0')
                        year_val[year] = value

                years_sorted = sorted(year_val.keys(), reverse=True)
                slots = ['year_1', 'year_2', 'year_3']
                res = {}
                for i, year in enumerate(years_sorted[:3]):
                    val = year_val[year]
                    res[slots[i]] = f"{{'{year}': '{val}'}}"
                return res
    return {'year_1': '', 'year_2': '', 'year_3': ''}


def extract_financial_results(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —É–¥–∞–ª—è—è —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∑–Ω–∞—á–µ–Ω–∏–π (–∑–∞–≥–æ–ª–æ–≤–∫–∏)."""
    financial_results = {}
    year_indices = {}

    for table in doc.tables:
        if len(table.rows) < 2 or len(table.columns) < 2:
            continue

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        header_row = table.rows[0]
        header_cells = [extract_text_without_strikethrough(cell.paragraphs[0]).strip()
                        for cell in header_row.cells if cell.paragraphs]

        temp_year_indices = {}
        for idx, text in enumerate(header_cells):
            match = re.search(r'(?:–∫–æ–Ω–µ—Ü\s*)?(20\d{2})', text.lower())
            if match:
                year = match.group(1)
                temp_year_indices[year] = idx

        if len(temp_year_indices) < 2:
            continue

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–æ –Ω—É–∂–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–ø–æ –∫–ª—é—á—É "–í—ã—Ä—É—á–∫–∞")
        has_revenue_row = any(
            "–≤—ã—Ä—É—á–∫–∞" in extract_text_without_strikethrough(row.cells[0].paragraphs[0]).strip().lower()
            for row in table.rows if row.cells and row.cells[0].paragraphs
        )
        if not has_revenue_row:
            continue

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≥–æ–¥–∞
        sorted_years = sorted(temp_year_indices.keys())

        for row in table.rows[1:]:
            if len(row.cells) < max(temp_year_indices.values()) + 1:
                continue

            row_name = extract_text_without_strikethrough(row.cells[0].paragraphs[0]).strip() if row.cells[0].paragraphs else ''
            if not row_name:
                continue

            values = {}
            all_none = True

            for year, idx in temp_year_indices.items():
                val = ''
                if idx < len(row.cells) and row.cells[idx].paragraphs:
                    val = extract_text_without_strikethrough(row.cells[idx].paragraphs[0]).strip()

                val_clean = val.replace(' ', '').replace('‚Äì', '').strip()
                if val_clean:
                    values[year] = val_clean
                    all_none = False
                else:
                    values[year] = None

            if not all_none:
                financial_results[row_name] = values

        break  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é —Ç–∞–±–ª–∏—Ü—É

    return financial_results


def extract_assets_and_receivables(doc):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤–∞—Ö –∏ –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏."""
    result = {
        "–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": {},
        "–î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å": {}
    }

    for table in doc.tables:
        header_cells = [extract_text_without_strikethrough(cell.paragraphs[0]).strip().lower()
                        for cell in table.rows[0].cells if cell.paragraphs]
        year_to_col = {}

        for idx, txt in enumerate(header_cells):
            m = re.search(r'–∫–æ–Ω–µ—Ü\s*(20\d{2})', txt)
            if m:
                year_to_col[m.group(1)] = idx

        if len(year_to_col) >= 3:
            years_sorted = sorted(year_to_col.keys(), reverse=True)[:3]
            row_–æ—Å = None
            row_–¥–µ–±–∏—Ç = None

            for row in table.rows:
                first_cell = extract_text_without_strikethrough(row.cells[0].paragraphs[0]).strip().lower() if \
                row.cells[0].paragraphs else ''
                if first_cell == "–æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞":
                    row_–æ—Å = row
                if first_cell == "–¥–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å":
                    row_–¥–µ–±–∏—Ç = row

            if row_–æ—Å and row_–¥–µ–±–∏—Ç:
                for i, year in enumerate(years_sorted):
                    idx = year_to_col[year]
                    val_os = extract_text_without_strikethrough(row_–æ—Å.cells[idx].paragraphs[0]).strip().replace(' ',
                                                                                                                 '').replace(
                        '‚Äì', '0') if idx < len(row_–æ—Å.cells) and row_–æ—Å.cells[idx].paragraphs else '0'
                    val_db = extract_text_without_strikethrough(row_–¥–µ–±–∏—Ç.cells[idx].paragraphs[0]).strip().replace(' ',
                                                                                                                    '').replace(
                        '‚Äì', '0') if idx < len(row_–¥–µ–±–∏—Ç.cells) and row_–¥–µ–±–∏—Ç.cells[idx].paragraphs else '0'
                    result["–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞"][f'year_{i + 1}'] = {year: val_os}
                    result["–î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å"][f'year_{i + 1}'] = {year: val_db}
                break

    return result


def extract_related_companies_from_path(filepath):

    full_text = docx2txt.process(filepath)

    if not full_text or "–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏ ‚Äì –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ" not in full_text:
        print("–ë–ª–æ–∫ '–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏ ‚Äì –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return {"–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏": {}}

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –±–ª–æ–∫ "–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏ ‚Äì –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ"
    block_lines = full_text.split("–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏ ‚Äì –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ", 1)[-1].splitlines()
    cleaned_block_lines = []
    for line in block_lines:
        if "–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏ ‚Äì" in line and "–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ" not in line:
            break
        cleaned_block_lines.append(line.strip())

    lines = [l for l in cleaned_block_lines if l]

    related_companies = {}
    current = None
    current_key = None
    last_key_was_participant = False  # —á—Ç–æ–±—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞—Ç—å –º—É—Å–æ—Ä –∏–∑ —Å—Ç—Ä–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤

    for i, line in enumerate(lines):
        clean_line = line.lstrip("‚ñ∂‚ñ∫‚Ä¢").strip()

        # –ü—Ä–æ–ø—É—Å–∫ –º—É—Å–æ—Ä–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        if ("–∫–æ–Ω—Ç—É—Ä.—Ñ–æ–∫—É—Å" in clean_line.lower()
                or "–ø–æ –¥–∞–Ω–Ω—ã–º" in clean_line.lower()
                or "–Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏" in clean_line.lower()):
            continue

        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ –∫–ª—é—á–æ–º "–£—á–∞—Å—Ç–Ω–∏–∫–∏", —ç—Ç—É –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if last_key_was_participant:
            last_key_was_participant = False
            continue

        # –ù–æ–≤—ã–π –±–ª–æ–∫ –∫–æ–º–ø–∞–Ω–∏–∏
        if re.match(r'^(–û–û–û|–ê–û|–ü–ê–û|–ò–ü)\s', clean_line):
            # –ü—Ä–∏–∑–Ω–∞–∫–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞: –ò–ù–ù + %, –∏–ª–∏ —Ä—É–±., –∏–ª–∏ "–¥–æ–ª—è"
            if re.search(r'–ò–ù–ù.*\d{10,12}.*(%|—Ä—É–±\.|–¥–æ–ª—è)', clean_line.lower()):
                continue
            if "%" in clean_line or "–¥–æ–ª—è" in clean_line.lower() or "—Ä—É–±" in clean_line.lower():
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
            normalized_key = re.sub(r'\s+', '', clean_line).lower()
            if any(re.sub(r'\s+', '', k).lower() == normalized_key for k in related_companies):
                continue

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –∫–æ–º–ø–∞–Ω–∏—é
            if current_key and current:
                related_companies[current_key] = current

            current_key = clean_line
            current = {
                "–ê–¥—Ä–µ—Å": "",
                "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä": "" if current_key.startswith("–ò–ü") else "",
                "–£—á–∞—Å—Ç–Ω–∏–∫–∏": [] if current_key.startswith("–ò–ü") else [],
                "–†–µ–∫–≤–∏–∑–∏—Ç—ã": {"–ò–ù–ù": "", "–û–ì–†–ù": ""}
            }
            continue

        if not current:
            continue

        # –†–µ–∫–≤–∏–∑–∏—Ç—ã
        if "–∏–Ω–Ω" in clean_line.lower() or "–æ–≥—Ä–Ω" in clean_line.lower():
            _, inn, ogrn = extract_inn_ogrn(clean_line)
            if inn:
                current["–†–µ–∫–≤–∏–∑–∏—Ç—ã"]["–ò–ù–ù"] = inn
            if ogrn:
                current["–†–µ–∫–≤–∏–∑–∏—Ç—ã"]["–û–ì–†–ù"] = ogrn

        # –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä
        if "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä" in clean_line and i + 1 < len(lines):
            fio_line = lines[i + 1]
            cleaned, inn, _ = extract_inn_ogrn(fio_line)
            result = f"{cleaned}, –ò–ù–ù {inn}" if inn else cleaned
            current["–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä"] = result

        # –£—á–∞—Å—Ç–Ω–∏–∫–∏
        if ("—É—á—Ä–µ–¥–∏—Ç–µ–ª—å" in clean_line.lower() or "—É—á–∞—Å—Ç–Ω–∏–∫" in clean_line.lower()) and i + 1 < len(lines):
            full_text = lines[i + 1]
            participant = full_text.split("100%")[0].strip() + "100%" if "100%" in full_text else full_text
            participant = re.sub(r"\xa0", " ", participant)
            current["–£—á–∞—Å—Ç–Ω–∏–∫–∏"].append(participant)
            last_key_was_participant = True
            continue

        # –ê–¥—Ä–µ—Å
        if clean_line.lower() == "–∞–¥—Ä–µ—Å" and i + 1 < len(lines):
            current["–ê–¥—Ä–µ—Å"] = lines[i + 1]
        elif not current["–ê–¥—Ä–µ—Å"] and re.search(r'(–≥\.|–≥ |–æ–±–ª\.|–æ–±–ª |—Ä–µ—Å–ø\.|—Ä–µ—Å–ø )', clean_line.lower()):
            current["–ê–¥—Ä–µ—Å"] = clean_line

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∫–æ–º–ø–∞–Ω–∏—é
    if current_key and current:
        related_companies[current_key] = current

    return related_companies


def parsing_all_docx(docx_path):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    company_data = {
        '–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': '',
        '–ò–ù–ù': '',
        '–ö–ü–ü': '',
        '–û–ì–†–ù': '',
        '–î–∞—Ç–∞ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è': '',
        '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å': '',
        '–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª': '',
        '–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä': '',
        '–ö–æ–Ω–∫—É—Ä—Å–Ω—ã–π —É–ø—Ä–∞–≤–ª—è—é—â–∏–π': '',  # <== –¥–æ–±–∞–≤–∏–ª–∏ –∫–ª—é—á
        '–£—á—Ä–µ–¥–∏—Ç–µ–ª–∏/—É—á–∞—Å—Ç–Ω–∏–∫–∏': [],
        '–û–ö–í–≠–î(–æ—Å–Ω–æ–≤–Ω–æ–π)': '',
        '–°–≤–µ–¥–µ–Ω–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö': {
            '–°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å': {'year_1': '', 'year_2': '', 'year_3': ''},
            '–†–∞—Å—Ö–æ–¥—ã –Ω–∞ –æ–ø–ª–∞—Ç—É —Ç—Ä—É–¥–∞': {'year_1': '', 'year_2': '', 'year_3': ''},
        },
        '–°–≤–µ–¥–µ–Ω–∏—è –æ –∑–∞–ª–æ–≥–∞—Ö': [],
        '–°–≤–µ–¥–µ–Ω–∏—è –æ –ª–∏–∑–∏–Ω–≥–µ': [],
        '–ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å': {'year_1': '', 'year_2': '', 'year_3': ''},
        '–û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö': {},
        '–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∏ –¥–µ–±–∏—Ç–æ—Ä–∫–∞': {
            '–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞': {},
            '–î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å': {}
        },
        '–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏': []
    }

    if not os.path.isfile(docx_path):
        print(f"–§–∞–π–ª '{docx_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return company_data

    try:
        doc = Document(docx_path)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        basic_info = extract_basic_info(doc)
        staff_info = extract_staff_info(doc)
        founders = extract_founders(doc)
        collaterals = extract_collaterals(doc)
        leasing_info = extract_leasing_info(doc)
        credit_debt = extract_credit_debt(doc)
        financial_results = extract_financial_results(doc)
        assets_receivables = extract_assets_and_receivables(doc)
        competitive_manager = extract_competitive_manager(doc)
        related_companies = extract_related_companies_from_path(docx_path)

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        company_data.update(basic_info)
        company_data['–°–≤–µ–¥–µ–Ω–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö'] = staff_info
        company_data['–£—á—Ä–µ–¥–∏—Ç–µ–ª–∏/—É—á–∞—Å—Ç–Ω–∏–∫–∏'] = founders
        company_data['–°–≤–µ–¥–µ–Ω–∏—è –æ –∑–∞–ª–æ–≥–∞—Ö'] = collaterals
        company_data['–°–≤–µ–¥–µ–Ω–∏—è –æ –ª–∏–∑–∏–Ω–≥–µ'] = leasing_info
        company_data['–ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å'] = credit_debt
        company_data['–û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö'] = financial_results
        company_data['–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∏ –¥–µ–±–∏—Ç–æ—Ä–∫–∞'] = assets_receivables
        company_data['–ö–æ–Ω–∫—É—Ä—Å–Ω—ã–π —É–ø—Ä–∞–≤–ª—è—é—â–∏–π'] = competitive_manager
        company_data['–ë–ª–∏–∂–∞–π—à–∏–µ —Å–≤—è–∑–∏'] = related_companies

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ '{docx_path}': {e}")

    return company_data


if __name__ == "__main__":
    docx_path = os.path.join(os.path.dirname(__file__), "word.docx")
    result = parsing_all_docx(docx_path)
    from pprint import pprint

    pprint(result)